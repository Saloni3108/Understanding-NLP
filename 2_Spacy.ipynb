{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Spacy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-t3P0VuAVhT"
      },
      "source": [
        "## NLP using Spacy - Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjmIl_l_AbC2",
        "outputId": "6c656610-91a9-4f1e-b9d5-cde3ef461720"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acS9z-wKAeHE"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyq-Ud0wAqY5"
      },
      "source": [
        "## 1. Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlIexJuKAoNp",
        "outputId": "91ddd53c-e093-43d8-e85d-7ff3ffd10cc5"
      },
      "source": [
        "txt = ('I am going to learn deep neural networks now only.')\n",
        "intro = nlp(txt)\n",
        "# Extract tokens for the given doc\n",
        "print ([token.text for token in intro])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'going', 'to', 'learn', 'deep', 'neural', 'networks', 'now', 'only', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEttVqfGAzub"
      },
      "source": [
        "## 2. Sentence Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wN1NC5Au7C",
        "outputId": "7e09904b-b62a-46ea-8355-bbbfb3402d7e"
      },
      "source": [
        "about_text = ('Bob Ross is a Python developer currently'\n",
        "              ' working for a London-based Fintech'\n",
        "              ' company. He is interested in learning'\n",
        "              ' Natural Language Processing.')\n",
        "about_doc = nlp(about_text)\n",
        "sentences = list(about_doc.sents)\n",
        "print(len(sentences))\n",
        "\n",
        "for sentence in sentences:\n",
        "     print (sentence)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Bob Ross is a Python developer currently working for a London-based Fintech company.\n",
            "He is interested in learning Natural Language Processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbv_u11rA4aL",
        "outputId": "cd36b73f-0961-41a4-b7c6-52ed127479f6"
      },
      "source": [
        "txt = ('I am going to play'\n",
        "              ' football in new delhi'\n",
        "              ' after'\n",
        "              ' two days.')\n",
        "doc = nlp(txt)\n",
        "sentences = list(doc.sents)\n",
        "print(len(sentences))\n",
        "\n",
        "for sentence in sentences:\n",
        "     print (sentence)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "I am going to play football in new delhi after two days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5abaTsHkBAWI"
      },
      "source": [
        "## 3. Stop Words - Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRDV1bxDA7Ou",
        "outputId": "79a8a722-8fbb-4bc6-fc44-8297c8868311"
      },
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "len(spacy_stopwords)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__eY5jNZBHAL",
        "outputId": "b2003317-c667-40ad-fb17-956366e8d75b"
      },
      "source": [
        "for stop_word in list(spacy_stopwords)[:11]:\n",
        "  print(stop_word)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "each\n",
            "itself\n",
            "another\n",
            "would\n",
            "which\n",
            "why\n",
            "via\n",
            "off\n",
            "regarding\n",
            "through\n",
            "always\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nSPvnkCBJGv",
        "outputId": "3a5c0731-abc1-4505-88cd-e7af503fae7e"
      },
      "source": [
        "for token in about_doc:\n",
        "     if not token.is_stop:\n",
        "         print (token)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bob\n",
            "Ross\n",
            "Python\n",
            "developer\n",
            "currently\n",
            "working\n",
            "London\n",
            "-\n",
            "based\n",
            "Fintech\n",
            "company\n",
            ".\n",
            "interested\n",
            "learning\n",
            "Natural\n",
            "Language\n",
            "Processing\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBKm61SCBRVI"
      },
      "source": [
        "##4. Lemmatization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f24FI0jBMsI",
        "outputId": "5c22002c-955c-48c7-ca9f-dcc03afe7b04"
      },
      "source": [
        "conference_help_text = ('She is helping organize a developer'\n",
        "    'conference on Applications of Natural Language'\n",
        "     ' Processing. He keeps organizing local Python meetups'\n",
        "     ' and several internal talks at his workplace.')\n",
        "conference_help_doc = nlp(conference_help_text)\n",
        "for token in conference_help_doc:\n",
        "     print (token, token.lemma_)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She -PRON-\n",
            "is be\n",
            "helping help\n",
            "organize organize\n",
            "a a\n",
            "developerconference developerconference\n",
            "on on\n",
            "Applications Applications\n",
            "of of\n",
            "Natural Natural\n",
            "Language Language\n",
            "Processing Processing\n",
            ". .\n",
            "He -PRON-\n",
            "keeps keep\n",
            "organizing organize\n",
            "local local\n",
            "Python Python\n",
            "meetups meetup\n",
            "and and\n",
            "several several\n",
            "internal internal\n",
            "talks talk\n",
            "at at\n",
            "his -PRON-\n",
            "workplace workplace\n",
            ". .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th6qeBlvBf7O"
      },
      "source": [
        "## 5. Work Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v3gU0TzBe_p"
      },
      "source": [
        "from collections import Counter\n",
        "complete_text = ('Bran Adams is a Python developer currently'\n",
        "    'working for a London-based Fintech company. He is'\n",
        "    ' interested in learning Natural Language Processing.'\n",
        "    ' There is a developer conference happening on 21 July'\n",
        "    ' 2019 in London. It is titled \"Applications of Natural'\n",
        "    ' Language Processing\". There is a helpline number '\n",
        "    ' available at +1-1234567891. Bran is helping organize it.'\n",
        "    ' He keeps organizing local Python meetups and several'\n",
        "    ' internal talks at his workplace. Bran is also presenting'\n",
        "    ' a talk. The talk will introduce the reader about \"Use'\n",
        "    ' cases of Natural Language Processing in Fintech\".'\n",
        "    ' Apart from his work, he is very passionate about music.'\n",
        "    ' Bran is learning to play the Piano. He has enrolled '\n",
        "    ' himself in the weekend batch of Great Piano Academy.'\n",
        "    ' Great Piano Academy is situated in Mayfair or the City'\n",
        "    ' of London and has world-class piano instructors.')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzHE6JsdBku4",
        "outputId": "b4c29807-9e05-4152-8735-7d6872a14b75"
      },
      "source": [
        "complete_doc = nlp(complete_text)\n",
        "# Remove stop words and punctuation symbols\n",
        "words = [token.text for token in complete_doc\n",
        "          if not token.is_stop and not token.is_punct]\n",
        "\n",
        "word_freq = Counter(words)\n",
        "\n",
        "# 5 commonly occurring words with their frequencies\n",
        "common_words = word_freq.most_common(5)\n",
        "print (common_words)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Bran', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43HtSAKHBm-C",
        "outputId": "54acf989-4a5c-40b1-e891-2a506d529ac3"
      },
      "source": [
        "# Unique words\n",
        "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
        "print (unique_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Adams', 'currentlyworking', 'based', 'company', 'interested', 'conference', 'happening', '21', 'July', '2019', 'titled', 'Applications', 'helpline', 'number', 'available', '+1', '1234567891', 'helping', 'organize', 'keeps', 'organizing', 'local', 'meetups', 'internal', 'talks', 'workplace', 'presenting', 'introduce', 'reader', 'Use', 'cases', 'Apart', 'work', 'passionate', 'music', 'play', 'enrolled', 'weekend', 'batch', 'situated', 'Mayfair', 'City', 'world', 'class', 'piano', 'instructors']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhAznNQUBonX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}